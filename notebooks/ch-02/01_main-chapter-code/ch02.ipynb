{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc78bb16f41373f",
   "metadata": {},
   "source": [
    "## Download Example text"
   ]
  },
  {
   "cell_type": "code",
   "id": "9cb2ece60f2828a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:09:22.286986Z",
     "start_time": "2025-10-16T19:09:22.179765Z"
    }
   },
   "source": [
    "from llm_from_scratch.ch_02.text_file import TextFile\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "       \"the-verdict.txt\")\n",
    "file_path = '/Users/mustafa/Workspaces/learning/llms-from-scratch/src/llm_from_scratch/data/the-verdict.txt'\n",
    "print(file_path)\n",
    "tf = TextFile(url, file_path)\n",
    "tf.download()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/Workspaces/learning/llms-from-scratch/src/llm_from_scratch/data/the-verdict.txt\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "29bd2fbb10a0e6b8",
   "metadata": {},
   "source": [
    "## Simple Tokenizer V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7a3028fa5963e",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "id": "8618f2d8f9bb2dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:09:28.439718Z",
     "start_time": "2025-10-16T19:09:28.434472Z"
    }
   },
   "source": [
    "from llm_from_scratch.ch_02.tokenizer import SimpleTokenizerV1\n",
    "\n",
    "tf.load()\n",
    "# build vocab\n",
    "tokenizer = SimpleTokenizerV1(tf.raw_text)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    " Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/mustafa/Workspaces/learning/llms-from-scratch/src/llm_from_scratch/data/the-verdict.txt\n",
      "Length: 20479 characters\n",
      "\n",
      "First 500 characters:\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it'\n",
      "\n",
      "... (truncated)\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Carlo;', 25)\n",
      "('Chicago', 26)\n",
      "('Claude', 27)\n",
      "('Come', 28)\n",
      "('Croft', 29)\n",
      "('Destroyed', 30)\n",
      "('Devonshire', 31)\n",
      "('Don', 32)\n",
      "('Dubarry', 33)\n",
      "('Emperors', 34)\n",
      "('Florence', 35)\n",
      "('For', 36)\n",
      "('Gallery', 37)\n",
      "('Gideon', 38)\n",
      "('Gisburn', 39)\n",
      "('Gisburns', 40)\n",
      "('Grafton', 41)\n",
      "('Greek', 42)\n",
      "('Grindle', 43)\n",
      "('Grindle:', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n",
      "[1, 58, 2, 872, 1013, 615, 541, 763, 5, 1155, 608, 5, 1, 69, 7, 39, 873, 1136, 773, 812, 7]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "10911e167978a578",
   "metadata": {},
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5ae58d6ed474849",
   "metadata": {},
   "source": [
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7110a6a502dd741f",
   "metadata": {},
   "source": [
    "### SimpleTokenizerV1: Encoding including Unknown Tokens"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1057751-681f-417c-aea9-09a1a107e51f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "try:\n",
    "    text = \"Hello, do you like tea?\"\n",
    "    ids = tokenizer.encode(text)\n",
    "    print(ids)\n",
    "except Exception as e:\n",
    "    print(f\"Error encoding text: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2861f2aab66319a5",
   "metadata": {},
   "source": [
    "## Simple Tokenizer V2\n",
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "id": "9656137e-1d51-42d6-8bd4-905f0a9212af",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from llm_from_scratch.ch_02.tokenizer import SimpleTokenizerV2\n",
    "\n",
    "tokenizer = SimpleTokenizerV2(tf.raw_text)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    " Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8fd3a27815d0ef7c",
   "metadata": {},
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbf397f928e0607b",
   "metadata": {},
   "source": [
    "print(\"SimpleTokenizerV2: Decoding Ids to tokens \")\n",
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e21d4435c9e4f067",
   "metadata": {},
   "source": [
    "### Encoding including Unknown Tokens"
   ]
  },
  {
   "cell_type": "code",
   "id": "7ede492f-0d75-4285-a8d1-afd273374a2c",
   "metadata": {},
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "88641883af3805e4",
   "metadata": {},
   "source": [
    "### Decoding including Unknown Tokens"
   ]
  },
  {
   "cell_type": "code",
   "id": "d84819fb-e782-4607-87df-84c6da9d5fdd",
   "metadata": {},
   "source": [
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57bb418ac78d5863",
   "metadata": {},
   "source": [
    "### Decode multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "id": "00700433-3afe-428f-a378-015a9ce92c19",
   "metadata": {},
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cdfdb747e775b673",
   "metadata": {},
   "source": [
    "\n",
    "## BytePair encoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "a022ac1f-ef1d-469c-bd51-e8779a1d9cce",
   "metadata": {},
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "    \"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44d68b497b9d69b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "9d6d794695e30601",
   "metadata": {},
   "source": [
    "enc_text = tokenizer.encode(tf.raw_text)\n",
    "print(len(enc_text))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d10f7d651f3b506c",
   "metadata": {},
   "source": [
    "Next, we remove the first 50 tokens from the dataset for demonstration purposes, as it results in a slightly more interesting text passage in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5b74563debcde71",
   "metadata": {},
   "source": [
    "enc_sample = enc_text[50:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46ef4f0796c4d361",
   "metadata": {},
   "source": [
    "One of the easiest and most intuitive ways to create the inputâ€“target pairs for the next-word prediction task is to create two variables, x and y, where x contains the input tokens and y contains the targets, which are the inputs shifted by 1:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b521749c7ebac74",
   "metadata": {},
   "source": [
    "context_size = 4         #1\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64864ad5460e5a5d",
   "metadata": {},
   "source": [
    "By processing the inputs along with the targets, which are the inputs shifted by one position"
   ]
  },
  {
   "cell_type": "code",
   "id": "62b5bbbb30550462",
   "metadata": {},
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e23915cb62e7913",
   "metadata": {},
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "718da6b0c5ed6b1c",
   "metadata": {},
   "source": [
    "from llm_from_scratch.ch_02.gpt_dataset import create_dataloader_v1\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    text=tf.raw_text,\n",
    "    batch_size=1,\n",
    "    max_length=4,\n",
    "    stride=1,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ],
   "id": "3bea6d0014712097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Exercise 2.2 Data loaders with different strides and context sizes",
   "id": "e372b540329b6bc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:09:33.015293Z",
     "start_time": "2025-10-16T19:09:32.902374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llm_from_scratch.ch_02.gpt_dataset import create_dataloader_v1\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    text=tf.raw_text,\n",
    "    batch_size=1,\n",
    "    max_length=2,\n",
    "    stride=2,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "batch = next(data_iter)\n",
    "print(\"max_length=2 and stride=2\")\n",
    "print(batch)\n",
    "batch = next(data_iter)\n",
    "print(batch)\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    text=tf.raw_text,\n",
    "    batch_size=1,\n",
    "    max_length=8,\n",
    "    stride=2,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "batch = next(data_iter)\n",
    "print(\"max_length=8 and stride=2\")\n",
    "print(batch)\n",
    "batch = next(data_iter)\n",
    "print(batch)"
   ],
   "id": "a881dde036919897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=2 and stride=2\n",
      "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
      "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n",
      "max_length=8 and stride=2\n",
      "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
      "[tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Batch sizes",
   "id": "9b5749f296a2381c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:09:35.838698Z",
     "start_time": "2025-10-16T19:09:35.828072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    text = tf.raw_text, \n",
    "    batch_size=8, \n",
    "    max_length=4,\n",
    "    stride=4, # using stride 4 avoids any overlap between the batches since more overlap could lead to increased overfitting\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ],
   "id": "2ce14cf45d9f07b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Creating token embeddings"
   ],
   "id": "a5b18327a90ded78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:35:03.816665Z",
     "start_time": "2025-10-16T19:35:03.805562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# for the sake of simplicity\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6 # suppose we have a small vocabulary of only 6 words\n",
    "output_dim = 3 # we want to create embeddings of size 3\n",
    "# Using the vocab_size and output_dim, we can instantiate an embedding layer in PyTorch\n",
    "torch.manual_seed(123) # for reproducibility\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "print(embedding_layer.weight)"
   ],
   "id": "d9fb990b3882a76f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The weight matrix of the embedding layer contains small, random values. These values are optimized during LLM training as part of the LLM optimization itself. Moreover, we can see that the weight matrix has six rows and three columns. There is one row for each of the six possible tokens in the vocabulary, and there is one column for each of the three embedding dimensions.",
   "id": "313a1ee14a61207d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:36:55.551630Z",
     "start_time": "2025-10-16T19:36:55.548559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, letâ€™s apply it to a token ID to obtain the embedding vector:\n",
    "print(embedding_layer(torch.tensor([3])))"
   ],
   "id": "34a143ea966c294a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "the embedding layer is essentially a lookup operation that retrieves rows from the embedding layerâ€™s weight matrix via a token ID",
   "id": "3b2b3fef259cd607"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:40:40.692420Z",
     "start_time": "2025-10-16T19:40:40.689132Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_layer(input_ids))",
   "id": "a0b52a96f9dacecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Positional embeddings",
   "id": "fa67c720380c9e4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:52:06.364729Z",
     "start_time": "2025-10-16T19:52:06.240860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a token embedding layer with 50257 (the size of the GPT-2 vocabulary) and 256 (the size of the embedding dimension)\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "# if we sample data from the data loader, we embed each token in each batch into a 256-dimensional vector.\n",
    "# If we have a batch size of 8 with four tokens each, the result will be an 8 Ã— 4 Ã— 256 tensor.\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    text=tf.raw_text,\n",
    "    batch_size=8,\n",
    "    max_length=max_length,\n",
    "    stride=max_length, # no overlap between inputs\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ],
   "id": "b17ea0ab63a6ac07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:52:33.669897Z",
     "start_time": "2025-10-16T19:52:33.667384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "\n",
    "print(token_embeddings.shape)"
   ],
   "id": "60e505e2c9ce2aeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GPT modelâ€™s absolute embedding approach",
   "id": "4a46488940a23765"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:55:36.528732Z",
     "start_time": "2025-10-16T19:55:36.525831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ],
   "id": "c7e5b8875d4623e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:10:55.760989Z",
     "start_time": "2025-10-16T20:10:55.758806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PyTorch will add the 4 Ã— 256â€“dimensional pos_embeddings to token_embeddings via metrics add operation\n",
    "# we will then end up with a unique victor for each token that encode the positional information as well.\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ],
   "id": "6c785c939523737a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
